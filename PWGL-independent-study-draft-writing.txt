_Some Comments Arising From Using/Learning to Use PWGL_

One obvious problem is also a virtue, ultimately: learning how to express whatever you're thinking in Lisp. Much of this essay is connected to the challenge that this poses, regardless of the particular language chosen.

Because already having a grasp of Lisp will only get you so far in PWGL. The number of "library" or package-specficic functions available suggest that you _can_ choose to reinvent the wheel, as it were, especially if you're fully adept at Lisp; simply figure out what you want and then do all your work in the Lisp code boxes, coding things up from scratch as needs be. Or, you can just learn to use someone else's system. 

In this case, the available systems come with many merits, but being able to appreciate those merits comes with a not inconsiderable cost of having to scrape together your own understanding of the many interrelated systems's inner-workings. Such costs would be mitigated of course by some readily accessible handbook or manual. Which brings us to the help facilities.

The tutorial provided for PWGL (and for ENP) is available as patches directly in PWGL, or as a standalone pdf, which suggests that it is a book. Unfortunately, this book is actually just a straight dump of the tutorial patches into a pdf format.

What is needed, instead, is a more comprehensive text, which can be read on its own, in lucid, idiomatic English (or whatever language), fully elaborating on any concepts that require unpacking where needed. Now, determining the necessary level of detail in any explanation is always difficult, but the niceties of proper discourse all too often go out the window when it comes to software documentation. And as Richard Stallman has said, "writing good English is a rare skill among programmers."

It seems there's a useful distinction between a tutorial and a manual. A tutorial will--depending on its author--give you some clear examples of what you can do, and drop gnomic clues as to how and why it works that way. A fully-realized (and sympathetic) manual would instead unfold with a kind of measured argumentation, making claims or assertions, illustrating them, and then suggesting additional areas of inquiry and ways to go about pursuing them. Short of that, most documentation is, unfortunately, equivalent to saying, "Good luck!"

The cost associated with figuring out how the many complex pieces of PWGL fit together creates a disincentive to follow a method I have found extremely helpful in learning to use patching environments: starting with a blank slate at least every few sessions. When treating patches as if they were instruments rather than drafts, as existing applications requiring some modification rather than provisional programming environments requiring constant re-evaluation (terrible PWGL/Lisp pun unintended), we create problems for our own learning process, I venture.

Now this may be entirely a personal thing, but I believe that there is some wisdom to this way of working, at least when it comes to learning as opposed to production. Starting regularly with a blank slate--an empty patch--requires you to have at least a partial understanding of the tools available to you at that time, not just a vague recollection of what you did last time. The path to understanding may be through many such vague recollections, but your ultimate goal should be, when approaching things pedagogically, to create novel combinations of things you understand. When you lack this understanding, or aren't able to acquire it quickly enough, you too often end up reviewing the already documented purpose of this particular arrangement of objects you're now apprehensive to change.

Allow me to make a general observation and begin shifting away from talking about PWGL directly. 

When growing up, we don't learn language by being given a dictionary and a grammar book and told, "Go." What happens instead? There's no shortage of debate about this question, but I would speculate that what happens is this, at least in part. We develop over time an informal grasp of vocabulary and the idiomatic ways of combining the primitive elements of that vocabulary, words. When we make minor grammatical mistakes or need to refine our understanding of a word or construction, the plasticity of the brain and the fluidity of our original conceptions allow us to make adjustments quite naturally (I am here finessing the notion of an innate Universal Grammar put forward by Chomsky, of course).

Learning to program is both simpler and more complex. Simpler because the rules of combination highly constrain our available expressions, reducing the set of possible constructions to a manageable size. And these rules are explicity accounted for by a fixed system, such as a language specification or some other formal definition. If a statement in a computer language is well-formed, there should be no question of what it means, or will mean. Natural language expression and communication, on the other hand, is more fluid and, at times, equivocal; it relies on a complex mix of inference, shared or assumed context, and associative logic--all of which tend to leave room for interpretation, and potential confusion.

But this openness can also help make the task of expressing ourselves and being understood easier as well, as when a non-native speaker poses an ill-formed question whose meaning is nevertheless clear. And since abiding by a strict system often comes with hidden costs, like having to change our behavior and conform to what may seem like arbitrary rules and distinctions, conducting ourselves "by the book" in all cases is very different from being able to sometimes break rules without a penalty, as regularly happens in everyday conversation.

So, I would suggest that an ideal approach to learning to express our thoughts in a computer language is the following. We should strive to master a limited set of the available primitive expressions offered by a language, learning to produce a few _meaningful_ --as opposed to just allowable--combinations of such things in whatever time we require (what constitutes "meaningful" is a whole other story). As we develop, we can begin incrementally adding new such "primitives" (or functions, if you're programming Lisp), and see how that affects our ability to form new combinations. "Gradually expand awareness" may seem like an obvious maxim, but too often the ad hoc nature of our software set-ups interferes with our ability to follow through on it.

Now, few would deny the appeal of such an approach. It seems to reflect the process we follow in learning our most crucial logical system (a process that has more or less succeeded if we're able to read this). By which system I mean, of course, language itself and the modes of expression it makes possible. 

But simply recognizing that there are benefits to such incremental learning does not itself ensure a human-centric design to the tools available to us when learning to program. Such thinking must be built into the systems that we use. And because our computer languages reject ambiguities that our natural language understanding copes with, we have to recognize and take advantage this ability when it comes time to work through the more formal aspects of learning to program. It will only further humanize the process. 

Treating programming as just a peculiar mode of natural expression brings other advantages. Chief among them is that doing so can demystify what is for many people a mystifying, if not unnatural, form of thinking and communicating. However we choose to portray it, "computer language acquisition" being taught without an accompanying examination of natural language acquisition would seem to be missing an opportunity to make wider connections that can only help us.

Now, actually drawing out these parallels to natural expression and making them explicit (not just to ourselves but to others who lack the motivation we have as self-learners) is no small task. We can at least begin by promoting a conception of programming that makes it seem more like an ordinary activity. Everyday, we perform many non-trivial cognitive acts seemingly without effort. Namely, we have thoughts (often quite complex ones), and express those thoughts in a way that others can understand. 

To allude again to the patching scenario, we don't wake up in the morning going, "Now, where's the documentation for all those thoughts that I was thinking yesterday and require again today to accomplish my goals?" When we start with blank slates as often as feasible--going back to the drawing board and rehearsing the same process again and again, with the inevitable slight variations that come with being a human and not a machine--we learn in the way that we did as children, stacking the same building blocks, making new towers and watching them topple when we've made a mistake.

To begin wrapping up, this writing will take a turn to the overtly philosophical in order think about some of the ramifications of the above argument.

Elaborating on the idea above of "expanding our awareness," this awareness probably takes of the form of an internal model of the state of our environment, "wherever" that may be, from a computer to an ecosystem. When we talk about child psychology and learning, we can perhaps draw useful parallels to the programmer (or anyone sitting down to create at a computer).

The state of the environment necessarily includes whatever existing conditions we can point to in it. We identify 'objects,' whether tangible or intangible, in this environment and seek to characterize the relationships between them or the unseen forces acting on them. But just as important (if not more important for us as learners ) is a concomitant awareness of the environment that also includes an anticipation of the ways everything may change: what new objects may arise or be introduced, and what effects they will have on the existing state. While this is all admittedly quite abstract, the link to programming shouldn't be hard to draw.

The most important thing, in terms of a pedagogical perspective on learning to program, is that this internal model should be subject to change, just as much as the environment itself is. In fact, the more impervious to change the environment seems, the more important it is to maintain a "soft vigilance" of this paradoxical fact: an apparently static environment does NOT mean our internal model of that environment should remain equally static.

An analogy to developmental psychology is apparent. For any young child, and indeed even for adults, the contents of the world, the forces that pervade it--all the things that are of a primarily "physical" or "natural" kind--are just not that likely to change drastically from one moment to the next. One's exposure to them, of course, is subject to change, at times radical change, as in going from being ON a boat, to being knocked OFF the boat into a body of water. But again, updating one's internal model in such a case is a not matter of taking into account some new 'thing' that did not exist before, but rather of becoming aware of some prexisting condition (or possibility).

In fact, it is difficult to think of a radical, "natural" change that is not simply a matter of change of degree rather than kind. What physical or biological conditions would have to change to make the world unrecognizable, to bring about unprecedented novelty? Gravity suddenly could become more or less powerful, but this is a matter of degree. Short of some change at, say, the atomic or subatomic level, whereby matter that was transformed from one state to another so alters the relatively stable "world of human things" that we do not recognize it, it is mostly controlled, "laboratory" environments (such as a computer) that are subject to such radical disruption.  

Now, the use of the qualifier "natural" in the above two paragraphs was meant to a anticipate an obvious objection to this idea that "there's nothing new under the sun." What about the products of human hands and good ol' ingenuity, wrought from "natural," mostly ordinary, or at least generally available, elements?

A quote from Hannah Arendt's The Human Condition (which describes at length her take on the nature of the "world of human affairs") now seems especially pertinent: "Modern natural science and technology, which no longer observe or take material from or imitate processes of nature but seem actually to act into it, seem, by the same token, to have carried irreversibility and human unpredictability into the natural realm..." Now, she immediately adds the assertion, "where no remedy can be found to undo what has been done," which takes us even further outside the scope of talking about programming in PWGL. But the appearance of the technological here brings us back nicely to programming.

Her larger argument in The Human Condition about the life process and the world of human affairs would seem to have very little to do with programming and algorithmic composition (after all it was published in 1958, just two years after the now famous Dartmouth Conference about AI). But it is precisely because of the way technology in the form of computation (as opposed to mechanical fabrication) is missing from a book which boldly addressed the ideas of 'work,' and 'speech,' that we must interrogate a proposal such as I have made, to treat programming "as just a peculiar mode of natural expression." 

Thankfully, this is not the place to do so.
